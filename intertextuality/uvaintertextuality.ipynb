{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# University of Virginia: Intertextuality Detection\n",
    "This notebook will set all of the parameters you need to run intertextuality detection on a corpus of interest. The code itself, however, is distributed across several different files and you are welcome to take a look at that. Anything that you should change as a matter of course is located in this file.\n",
    "\n",
    "This suit of code loads in a corpus, identifies all intertextuality according to set parameters and returns several summary visualizations.\n",
    "\n",
    "### Dependencies\n",
    "You will need to install the python Levenshtein library for this to function properly. You can do this using\n",
    "pip install python-Levenshtein\n",
    "\n",
    "### Caution:\n",
    "This will run significantly slower on Windows computers because I have disabled multithreading.\n",
    "\n",
    "## The Program:\n",
    "First you will need to load in the scripts that will conduct the actual analysis. Just run this cell and do not change anything here. These are required for the analysis to run properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prepare_corpus, index_corpus, detect_intertexuality, compile_and_filter_results, align_quotes, form_quote_system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the analysis\n",
    "Here you can specify what constitues a quote. You will can change these values. \n",
    "\n",
    "**seedlength** (Integer) specifies how many characters should be in the seed you will use to start the analysis. Ten seems to work well for English, four for Chinese, but your results may vary.\n",
    "\n",
    "**threshold** (Float between 1 and 0) specifies the precent similarity necessary to consider something a quote. .95 will return very similar matches, .6 will return very noisy ones.\n",
    "\n",
    "**matchlength** (Integer) sets the minimum length a string must be to be considered a match. 40 or longer works well for English, otherwise you will catch a lot of meaningless sentence fragments.\n",
    "\n",
    "**max_comp** (Integer) sets the length of the sliding window of characters to run the algorithm on. The lower the number, the faster the algorithm will run, but please do not set this below 100 (there is no upper limit). Lower numbers will result in more fragmentary results, but the ends will have less noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seedlength\n",
    "seedlength = 10\n",
    "\n",
    "# Matches must be above this percent similar. Use floats between 0 and 1\n",
    "# .8 works well for prose Chinese documents. .9 works well for prose\n",
    "# English\n",
    "threshold = .95\n",
    "\n",
    "# Set the minimum length of an acceptable match. The shorter the length\n",
    "# the more noisy the results are.\n",
    "matchlength = 20\n",
    "\n",
    "# Set this to limit the similarity comparison to last n characters\n",
    "# Set to None for no limit. Setting a limit significantly\n",
    "# speeds the calculations up.\n",
    "max_comp = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus Preperation\n",
    "How do you want to handle the corpus? Do you want to remove words or delete whitespace? You can also create an index to speed up the analysis with large corpora at the expense of disk space.\n",
    "\n",
    "**toremove** (String, filename) is a file with words to be removed. Put one word per line in this file.\n",
    "\n",
    "**deletewhitespace** (Boolean) lets you delete whitespace from the analysis\n",
    "\n",
    "**create_index** (Boolean) specifies if you want to create an Index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File that contains words or characters be removed from the analysis\n",
    "# One item per line in the file. This is probably not necessary for most English\n",
    "# analyses.\n",
    "toremove = \"remove.txt\"\n",
    "\n",
    "# Remove whitespace? If set to False, this will replace one or more white spaces with\n",
    "# a single space. Otherwise, all whitespace gets deleted.\n",
    "deletewhitespace = False\n",
    "\n",
    "####################\n",
    "# INDEXING OPTIONS #\n",
    "####################\n",
    "# Index the corpus? True to do so, False to skip\n",
    "# Indexing the corpus significantly speeds the analysis up when working with\n",
    "# large corpora, but will use significant system resources.\n",
    "create_index = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Information\n",
    "Here you can specify where your corpus is and how you want to handle it. \n",
    "\n",
    "**corpusfolder** (String, folder name) takes the name of the folder containing your corpus.\n",
    "\n",
    "**textstoanalyze** (String, filename) This is optional. If you only want to study certain files, place one file name per line in this text file. Otherwise, leave as None\n",
    "\n",
    "**corpuscomposition** (String, filename) is like the above file, but it limits the documents against which you compare the files in textstoanalyze. Set to None if you don't want to limit the analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusfolder = \"corpus\"\n",
    "\n",
    "\n",
    "# By default, the script will compare every document in the corpus\n",
    "# against every other document.\n",
    "# Optionally, you can provide a file with a list of titles to analyze\n",
    "# Set to None if you do not wish to use this. This will also default\n",
    "# to None if the listed file does not exist.\n",
    "# This file should just contain one filename per line seperated with a\n",
    "# carraige return.\n",
    "textstoanalyze = None\n",
    "\n",
    "# You can also limit the part of the corpus you want to compare against\n",
    "# By default the provided texts to analyze will be compared against all docs\n",
    "corpuscomposition = None\n",
    "\n",
    "# Align quotes occuring between the following documents. Provide at\n",
    "# least two. If None, all quotes will be aligned. If your corpus contains\n",
    "# signficant reuse, this may be slow.\n",
    "alignment_docs = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Information\n",
    "Configure how the information is output. \n",
    "\n",
    "**result_directory** (String, foldername) will contain the files generated by the intertextuality algorithm. This will be amalgamated into\n",
    "\n",
    "**filteredresultfile** (String, filename) is the name of the file with the compiled results.\n",
    "\n",
    "**alignmentoutput** (String, filename) is the name of the file for the aligned results.\n",
    "\n",
    "**DEBUG** (Boolean) If you set this to true, the model will start over every time you run it. Otherwise, it will track which files have already been studied. This is best to set to False if you are working with a large corpus that takes a long time.\n",
    "\n",
    "**edgefile** (String, filename) is the name of a file that contains network data for the intertextuality (which can be loaded directly into Gephi)\n",
    "\n",
    "**scorelimit** (Integer) is the minimum number of characters that must be shared between two documents to appear in the network stored in edgefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# GENERAL OUTPUT #\n",
    "##################\n",
    "# IMPORTANT!!!!! If DEBUG is set to True, this folder will be deleted if it exists!!!!!\n",
    "result_directory = 'results'\n",
    "\n",
    "# Intertextuality Output\n",
    "filteredresultfile = \"corpus_results.txt\"\n",
    "\n",
    "# Alignment Output\n",
    "alignmentoutput = \"corpus_alignment.txt\"\n",
    "\n",
    "\n",
    "# Debug:\n",
    "DEBUG = True\n",
    "\n",
    "\n",
    "#*******************#\n",
    "# OUTPUT FILE EDGES #\n",
    "#*******************#\n",
    "# Output\n",
    "edgefile = 'edgetable.csv'\n",
    "\n",
    "# Set a minimum threshold for similarity for recording an edge.\n",
    "# 100 means one 100-character quote\n",
    "# or alternatively ten 10-character quotes (or something like that)\n",
    "scorelimit = 100\n",
    "\n",
    "\n",
    "# contains the lengths of all the texts in the corpus. Used for viz.\n",
    "corpus_text_lengths = \"corpus_text_lengths.txt\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering Results\n",
    "Once you have calculated the quotes, you have the option of filtering quotes that occur very frequently. This may not be necessary for you, but it helps if you are catching a lot of stock phrases in your search.\n",
    "\n",
    "**filtercommon** (Boolean) Set to true to remove very common quotes\n",
    "\n",
    "**shortquotelength** (Integer) How long are these quotes?\n",
    "\n",
    "**repmax** (Integer) How many times is considered frequent?\n",
    "\n",
    "**filtersimilar** (Boolean) This will filter out phrases that are highly similar to the common phrases that are also being filtered. THis can slow down the operation significantly\n",
    "\n",
    "**similaritythreshold** (Float between 1 and 0) Percent of similarity to remove similar quotes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#**********************#\n",
    "# FILTERING PARAMETERS #\n",
    "#**********************#\n",
    "\n",
    "# Filter the common, short quotes?\n",
    "filtercommon = True\n",
    "# What length constitutes \"short\"?\n",
    "shortquotelength = 40\n",
    "# How many repetitions consitute common?\n",
    "repmax = 100\n",
    "\n",
    "# Should similar to the common ones be filtered?\n",
    "# This will add significant slowdown depending on how many\n",
    "# quotes are included\n",
    "filtersimilar = False\n",
    "# What is the similarity threshold?\n",
    "similaritythreshold = .8\n",
    "# Limit check? If this is true, similarity will only be checked\n",
    "# for quotes that start with the same characters. This speeds the\n",
    "# code up significantly\n",
    "limitcheck = True\n",
    "limextent = 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Options that don't need to be changed\n",
    "The following set of options can be changed but really need not be changed. These are mostly internal files that are intermediate in the analysis or options that can be complicated to deal with.\n",
    "\n",
    "#### Alignment Parameters\n",
    "You can set the parameters for the alignment algorithm, which takes the results of the intertextuality algorithm and finds an optimal alignment between matching quotes. You probably don't need to adjust any of these\n",
    "\n",
    "#### Maximium child tasks\n",
    "This is related to the multiprocessing module and ensures a balance between memory usage and speed. You can ignore this.\n",
    "\n",
    "#### Front loading\n",
    "You can optionally have the longest texts processed first. This will speed up the algorithm a bit but can make early stages seem slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match, mismatch, and gap scores\n",
    "matchscore = 1\n",
    "misalignscore = -1\n",
    "mismatchscore = -1\n",
    "\n",
    "# Limit the length of text that will be aligned\n",
    "# This significantly speeds up the algorithm when\n",
    "# aligning very long quotes. This divides the quotes\n",
    "# into blocks of chunklim length. It tries to divide\n",
    "# the chunks in places where the alignment is exact\n",
    "# So overlap looks at the 10 character before and after\n",
    "# the proposed break. When it finds rangematch exact\n",
    "# characters, it inserts a break in the middle.\n",
    "chunklim = 200\n",
    "overlap = 30\n",
    "rangematch = 12\n",
    "\n",
    "# This following setting is necessary because of the multiprocessing module\n",
    "# The higher the maxtasks, the faster the processing is but the more memory\n",
    "# use fluctuates. If index is around 2.5 GB, use 50 workers, 150 < 1 GB\n",
    "# Set to None if you don't want to have processes expire, but watch out for\n",
    "# large memory use spikes. The multiprocessing occurs at the document level,\n",
    "# so if you have fewer documents, you can also use fewer tasks\n",
    "maxchildtasks = 150\n",
    "\n",
    "# You can sort so the longest texts will be processed first. This will speed\n",
    "# up overall processing time at the cost of RAM usuage.\n",
    "frontloading = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Analysis\n",
    "The section below should not be changed. It sends the necessary information to the various packages, which then run. Run and enjoy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 documents of 56 completed\n",
      "1349894 from 56 documents.\n",
      "Analyzing text 1 vs 55 (length: 13584)\n",
      "Operation completed in 1.03 seconds (averaging 1.03, in total 1.03)\n",
      "Analyzing text 2 vs 54 (length: 14048)\n",
      "Operation completed in 0.87 seconds (averaging 0.95, in total 1.90)\n",
      "Analyzing text 3 vs 53 (length: 22974)\n",
      "Operation completed in 1.01 seconds (averaging 0.97, in total 2.92)\n",
      "Analyzing text 4 vs 52 (length: 44424)\n",
      "Operation completed in 1.42 seconds (averaging 1.08, in total 4.34)\n",
      "Analyzing text 5 vs 51 (length: 18295)\n",
      "Operation completed in 0.90 seconds (averaging 1.05, in total 5.24)\n",
      "Analyzing text 6 vs 50 (length: 23331)\n",
      "Operation completed in 0.95 seconds (averaging 1.03, in total 6.19)\n",
      "Analyzing text 7 vs 49 (length: 21333)\n",
      "Operation completed in 0.92 seconds (averaging 1.02, in total 7.11)\n",
      "Analyzing text 8 vs 48 (length: 2190)\n",
      "Operation completed in 0.58 seconds (averaging 0.96, in total 7.69)\n",
      "Analyzing text 9 vs 47 (length: 9675)\n",
      "Operation completed in 0.72 seconds (averaging 0.93, in total 8.41)\n",
      "Analyzing text 10 vs 46 (length: 549)\n",
      "Operation completed in 0.56 seconds (averaging 0.90, in total 8.97)\n",
      "Analyzing text 11 vs 45 (length: 16498)\n",
      "Operation completed in 0.87 seconds (averaging 0.89, in total 9.84)\n",
      "Analyzing text 12 vs 44 (length: 15302)\n",
      "Operation completed in 0.85 seconds (averaging 0.89, in total 10.69)\n",
      "Analyzing text 13 vs 43 (length: 14801)\n",
      "Operation completed in 0.92 seconds (averaging 0.89, in total 11.60)\n",
      "Analyzing text 14 vs 42 (length: 18596)\n",
      "Operation completed in 0.94 seconds (averaging 0.90, in total 12.54)\n",
      "Analyzing text 15 vs 41 (length: 52726)\n",
      "Operation completed in 1.53 seconds (averaging 0.94, in total 14.07)\n",
      "Analyzing text 16 vs 40 (length: 16877)\n",
      "Operation completed in 0.90 seconds (averaging 0.94, in total 14.97)\n",
      "Analyzing text 17 vs 39 (length: 17866)\n",
      "Operation completed in 0.83 seconds (averaging 0.93, in total 15.79)\n",
      "Analyzing text 18 vs 38 (length: 14118)\n",
      "Operation completed in 0.68 seconds (averaging 0.92, in total 16.47)\n",
      "Analyzing text 19 vs 37 (length: 13508)\n",
      "Operation completed in 0.76 seconds (averaging 0.91, in total 17.23)\n",
      "Analyzing text 20 vs 36 (length: 20675)\n",
      "Operation completed in 1.01 seconds (averaging 0.91, in total 18.24)\n",
      "Analyzing text 21 vs 35 (length: 1287)\n",
      "Operation completed in 0.63 seconds (averaging 0.90, in total 18.87)\n",
      "Analyzing text 22 vs 34 (length: 10116)\n",
      "Operation completed in 0.74 seconds (averaging 0.89, in total 19.62)\n",
      "Analyzing text 23 vs 33 (length: 34360)\n",
      "Operation completed in 0.99 seconds (averaging 0.90, in total 20.61)\n",
      "Analyzing text 24 vs 32 (length: 19825)\n",
      "Operation completed in 0.76 seconds (averaging 0.89, in total 21.37)\n",
      "Analyzing text 25 vs 31 (length: 19607)\n",
      "Operation completed in 0.74 seconds (averaging 0.88, in total 22.11)\n",
      "Analyzing text 26 vs 30 (length: 10265)\n",
      "Operation completed in 0.61 seconds (averaging 0.87, in total 22.72)\n",
      "Analyzing text 27 vs 29 (length: 26341)\n",
      "Operation completed in 1.34 seconds (averaging 0.89, in total 24.06)\n",
      "Analyzing text 28 vs 28 (length: 17897)\n",
      "Operation completed in 0.73 seconds (averaging 0.89, in total 24.79)\n",
      "Analyzing text 29 vs 27 (length: 18407)\n",
      "Operation completed in 0.78 seconds (averaging 0.88, in total 25.56)\n",
      "Analyzing text 30 vs 26 (length: 52928)\n",
      "Operation completed in 1.21 seconds (averaging 0.89, in total 26.77)\n",
      "Analyzing text 31 vs 25 (length: 49059)\n",
      "Operation completed in 1.02 seconds (averaging 0.90, in total 27.79)\n",
      "Analyzing text 32 vs 24 (length: 22143)\n",
      "Operation completed in 0.62 seconds (averaging 0.89, in total 28.41)\n",
      "Analyzing text 33 vs 23 (length: 18941)\n",
      "Operation completed in 0.58 seconds (averaging 0.88, in total 28.98)\n",
      "Analyzing text 34 vs 22 (length: 48983)\n",
      "Operation completed in 0.92 seconds (averaging 0.88, in total 29.90)\n",
      "Analyzing text 35 vs 21 (length: 18338)\n",
      "Operation completed in 0.49 seconds (averaging 0.87, in total 30.39)\n",
      "Analyzing text 36 vs 20 (length: 20325)\n",
      "Operation completed in 0.50 seconds (averaging 0.86, in total 30.89)\n",
      "Analyzing text 37 vs 19 (length: 43855)\n",
      "Operation completed in 0.77 seconds (averaging 0.86, in total 31.67)\n",
      "Analyzing text 38 vs 18 (length: 12536)\n",
      "Operation completed in 0.48 seconds (averaging 0.85, in total 32.15)\n",
      "Analyzing text 39 vs 17 (length: 52943)\n",
      "Operation completed in 0.86 seconds (averaging 0.85, in total 33.00)\n",
      "Analyzing text 40 vs 16 (length: 15769)\n",
      "Operation completed in 0.50 seconds (averaging 0.84, in total 33.51)\n",
      "Analyzing text 41 vs 15 (length: 22336)\n",
      "Operation completed in 0.53 seconds (averaging 0.83, in total 34.04)\n",
      "Analyzing text 42 vs 14 (length: 51139)\n",
      "Operation completed in 0.81 seconds (averaging 0.83, in total 34.84)\n",
      "Analyzing text 43 vs 13 (length: 22016)\n",
      "Operation completed in 0.45 seconds (averaging 0.82, in total 35.29)\n",
      "Analyzing text 44 vs 12 (length: 22418)\n",
      "Operation completed in 0.43 seconds (averaging 0.81, in total 35.73)\n",
      "Analyzing text 45 vs 11 (length: 37786)\n",
      "Operation completed in 0.53 seconds (averaging 0.81, in total 36.26)\n",
      "Analyzing text 46 vs 10 (length: 46142)\n",
      "Operation completed in 0.60 seconds (averaging 0.80, in total 36.86)\n",
      "Analyzing text 47 vs 9 (length: 11350)\n",
      "Operation completed in 0.26 seconds (averaging 0.79, in total 37.13)\n",
      "Analyzing text 48 vs 8 (length: 18903)\n",
      "Operation completed in 0.27 seconds (averaging 0.78, in total 37.40)\n",
      "Analyzing text 49 vs 7 (length: 21214)\n",
      "Operation completed in 0.27 seconds (averaging 0.77, in total 37.66)\n",
      "Analyzing text 50 vs 6 (length: 39290)\n",
      "Operation completed in 0.40 seconds (averaging 0.76, in total 38.07)\n",
      "Analyzing text 51 vs 5 (length: 21669)\n",
      "Operation completed in 0.25 seconds (averaging 0.75, in total 38.31)\n",
      "Analyzing text 52 vs 4 (length: 19101)\n",
      "Operation completed in 0.17 seconds (averaging 0.74, in total 38.48)\n",
      "Analyzing text 53 vs 3 (length: 41888)\n",
      "Operation completed in 0.32 seconds (averaging 0.73, in total 38.80)\n",
      "Analyzing text 54 vs 2 (length: 24219)\n",
      "Operation completed in 0.17 seconds (averaging 0.72, in total 38.97)\n",
      "Analyzing text 55 vs 1 (length: 50789)\n",
      "Operation completed in 0.16 seconds (averaging 0.71, in total 39.14)\n",
      "Analyzing text 56 vs 0 (length: 14339)\n",
      "Operation completed in 0.01 seconds (averaging 0.70, in total 39.15)\n",
      "56 results of 56 processed.\n",
      "Counting short quotes\n",
      "Identifying high incidence quotes\n",
      "Removing high incidence quotes\n",
      "Global Operation completed in 0.22 seconds            \n",
      "Global Operation completed in 8.31 seconds\n"
     ]
    }
   ],
   "source": [
    "# set index and pickle file\n",
    "indexfile = 'index.db'\n",
    "picklefile = \"corpus.pickle\"\n",
    "\n",
    "prepare_corpus.run(picklefile, toremove, corpusfolder, deletewhitespace)\n",
    "\n",
    "if create_index:\n",
    "    index_corpus.run(seedlength, picklefile, indexfile)\n",
    "\n",
    "detect_intertexuality.run(seedlength, threshold, matchlength, max_comp, textstoanalyze, corpuscomposition, picklefile, indexfile, create_index, result_directory, maxchildtasks, frontloading, DEBUG)\n",
    "\n",
    "compile_and_filter_results.run(filtercommon, shortquotelength, repmax, filtersimilar, similaritythreshold, limitcheck,limextent, result_directory, filteredresultfile)\n",
    "\n",
    "form_quote_system.run(scorelimit, filteredresultfile, edgefile)\n",
    "\n",
    "align_quotes.run(alignment_docs,matchscore, misalignscore, mismatchscore, chunklim, overlap,rangematch, filteredresultfile, alignmentoutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
